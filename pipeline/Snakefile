# Snakemake pipeline for running mrScan package
#
#
# LICENSE: CC0. Do what you want with the code, but it has no guarantees.
#          https://creativecommons.org/share-your-work/public-domain/cc0/
#
#
#
# ./run_snakemake.sh
#
# don't forget to update cluster.yaml


import pandas as pd
import random
import string
import os.path
from snakemake.utils import validate

###### Load configuration file
configfile: "config.yaml"

#ss = pd.read_csv(config["input"]["sum_stats"], na_filter=False)

# output options
data_dir = config["out"]["data_dir"] #where the data is
out_dir = config["out"]["output_dir"] #where results will go
original_gwas_dir = config["out"]["gwas_dir"] # where originally download gwas data lives
formatted_gwas_dir = config["out"]["formatted_gwas_dir"] # where formatted gwas data lives

prefix = config["input"]["label"] + "_"
id_exposure = config["input"]["id_exposure"]
id_outcome = config["input"]["id_outcome"]
l2_dir = config["analysis"]["R"]["l2_dir"] # where LD score reference data lives

selection_type = []
if "classic_Lasso" in config["analysis"]["confounder_selection"]["method"]:
    classic_Lasso_string = expand("classic_Lasso_{lambda_type}_seed{seed}",
                              lambda_type = config["analysis"]["confounder_selection"]["lambda_type"],
                              seed = config["analysis"]["confounder_selection"]["seed"])
    selection_type.extend(classic_Lasso_string)

if "double_Lasso" in config["analysis"]["confounder_selection"]["method"]:
    double_Lasso_string = expand("double_Lasso_{lambda_type}_seed{seed}",
                              lambda_type = config["analysis"]["confounder_selection"]["lambda_type"],
                              seed = config["analysis"]["confounder_selection"]["seed"])
    selection_type.extend(double_Lasso_string)

if "stepwise" in config["analysis"]["confounder_selection"]["method"]:
    stepwise_string =  expand("stepwise_{stepwise_method}",
                              stepwise_method = config["analysis"]["confounder_selection"]["stepwise_method"])
    selection_type.extend(stepwise_string)

if "marginal" in config["analysis"]["confounder_selection"]["method"]:
    marginal_string = expand("marginal_p_{marginal_p}",
                              marginal_p = config["analysis"]["confounder_selection"]["marginal_p"])
    selection_type.extend(marginal_string)

if "corrected_Lasso" in config["analysis"]["confounder_selection"]["method"]:
    corrected_Lasso_string = expand("corrected_Lasso_{radius_type}_seed{seed}",
                                    radius_type = config["analysis"]["confounder_selection"]["radius_type"],
                                    seed = config["analysis"]["confounder_selection"]["seed"])
    selection_type.extend(corrected_Lasso_string)

if "double_corrected_Lasso" in config["analysis"]["confounder_selection"]["method"]:
    double_corrected_Lasso_string = expand("double_corrected_Lasso_{radius_type}_seed{seed}",
                                           radius_type = config["analysis"]["confounder_selection"]["radius_type"],
                                           seed = config["analysis"]["confounder_selection"]["seed"])
    selection_type.extend(double_corrected_Lasso_string)

if os.path.exists(data_dir + prefix + "qc_id_list.csv"):
    trait_id = pd.read_csv(data_dir + prefix + "qc_id_list.csv")['id'].tolist()

rule all:
    input:
        #data_dir + prefix + "qc_id_list.csv",
        #data_dir + prefix + "qc_trait_info.csv",
        #data_dir + prefix + "downstream_filter.RDS"
        #data_dir + prefix + "download.sh",
        #data_dir + prefix + "pairwise_cor.RDS",
        #data_dir + prefix + "unique_traits.RDS"
        expand(data_dir + prefix + "selection_{type}.RDS",type = selection_type)

rule extract_traits:
    params: id_exposure = id_exposure,
            id_outcome = id_outcome,
            batch = config["analysis"]["extract_traits"]["batch"],
            population = config["analysis"]["pop"],
            pval_instruments = config["analysis"]["pval_instruments"],
            pval_traits = config["analysis"]["extract_traits"]["pval_traits"],
            r2_thresh = config["analysis"]["ldprune"]["r2_thresh"],
            clump_kb = config["analysis"]["ldprune"]["clump_kb"],
            min_snps = config["analysis"]["extract_traits"]["min_snps"]
    output: out = data_dir + prefix + "extract_traits.RDS"
    script: 'R/1_extract_traits.R'

checkpoint quality_control:
    input: file = data_dir + prefix + "extract_traits.RDS"
    params: id_exposure = id_exposure,
            nsnp_cutoff = config["analysis"]["quality_control"]["nsnp_cutoff"],
            population = config["analysis"]["quality_control"]["pop"],
            sex = config["analysis"]["quality_control"]["sex"]
    output: id_list = data_dir + prefix + "qc_id_list.csv",
            trait_info = data_dir + prefix + "qc_trait_info.csv",
    script: 'R/2_quality_control.R'
    

def input_downstream(wcs):
    myfile = checkpoints.quality_control.get().output[0]
    trait_id = pd.read_csv(myfile)['id'].tolist()
    return expand(data_dir + prefix + "bidirection_{ID1}_{ID2}.RDS", ID1 = [id_exposure,id_outcome], ID2 = trait_id)    

rule extract_inst:
    params: pval_instruments = config["analysis"]["pval_instruments"],
            trait = "{ID}"
    output: out = data_dir + prefix + "inst_{ID}.RDS"
    script: "R/3_extract_inst.R"

rule bidirection_mr:
    input: file1 = data_dir + prefix + "inst_{ID1}.RDS",
           file2 = data_dir + prefix + "inst_{ID2}.RDS",
    params: method = config["analysis"]["bidirection_mr"]["method"],
            over_dispersion = config["analysis"]["bidirection_mr"]["over_dispersion"],
            loss_function = config["analysis"]["bidirection_mr"]["loss_function"]
    output: out = data_dir + prefix + "bidirection_{ID1}_{ID2}.RDS"
    script: "R/3_bidirection_mr.R"

rule downstream_filter:
    input: id_list = data_dir + prefix + "qc_id_list.csv", 
           mr_files = input_downstream,
           trait_info = data_dir + prefix + "qc_trait_info.csv"
    params: id_exposure = id_exposure,
            sig_level = config["analysis"]["downstream_filter"]["sig_level"],
            R2_cutoff = config["analysis"]["quality_control"]["R2_cutoff"]
    output: out = data_dir + prefix + "downstream_filter.RDS"
    script:"R/3_downstream_filter.R"

rule generate_download_file:
    input: file =  data_dir + prefix + "downstream_filter.RDS"
    params: path = original_gwas_dir,
            checkpoint = data_dir + prefix + "success_download.txt"
    output: out = data_dir + prefix + "download.sh"
    script:"R/4_download_data.R"

checkpoint download_gwas:
    input: data_dir + prefix + "download.sh"
    output: data_dir + prefix + "success_download.txt"
    shell: "bash {input}"

def input_combine_gwas(wcs):
    myfile = checkpoints.download_gwas.get().output[0]
    return data_dir + prefix + "downstream_filter.RDS"
                  
rule combine_gwas:
    input: file = input_combine_gwas
    params: path = original_gwas_dir
    output: out = data_dir + prefix + "all_beta.{chrom}.RDS"
    wildcard_constraints: chrom = "\d+"
    script:"R/4_combine_gwas.R"

rule calculate_cor:
    input: beta = expand(data_dir + prefix + "all_beta.{chrom}.RDS", chrom = range(1, 23)),
           m = expand(l2_dir + "{chrom}.l2.M_5_50", chrom = range(1, 23)),
           l2 = expand(l2_dir + "{chrom}.l2.ldscore.gz", chrom = range(1, 23))
    output: out = data_dir + prefix + "pairwise_cor.RDS"
    wildcard_constraints: pt = "[\d.]+"
    script: "R/4_ldsc_full.R"

rule unique_traits:
    input: file = data_dir + prefix + "downstream_filter.RDS",
           pairwise_cor = data_dir + prefix + "pairwise_cor.RDS"
    params: R2_cutoff = config["analysis"]["unique_traits"]["R2_cutoff"],
            method = config["analysis"]["unique_traits"]["method"]
    output: out = data_dir + prefix + "unique_traits.RDS"
    script: "R/4_unique_traits.R"

rule classic_Lasso:
    input: file = data_dir + prefix + "unique_traits.RDS"
    params: id_exposure = id_exposure,
            id_outcome = id_outcome,
            r2_thresh = config["analysis"]["confounder_selection"]["r2_thresh"],
            clump_kb = config["analysis"]["confounder_selection"]["clump_kb"],
            pval_threshold = config["analysis"]["confounder_selection"]["pval_threshold"],
            find_proxies = config["analysis"]["confounder_selection"]["find_proxies"],
            population = config["analysis"]["pop"],
            harmonise_strictness = config["analysis"]["confounder_selection"]["harmonise_strictness"],
            lambda_type = lambda wc: wc.get("lambda_type"),
            seed = config["analysis"]["confounder_selection"]["seed"]
    output: out = data_dir + prefix + "selection_classic_Lasso_{lambda_type}_seed{seed}.RDS"
    script: "R/5_classic_Lasso.R"

rule double_Lasso:
    input: file = data_dir + prefix + "unique_traits.RDS"
    params: id_exposure = id_exposure,
            id_outcome = id_outcome,
            r2_thresh = config["analysis"]["confounder_selection"]["r2_thresh"],
            clump_kb = config["analysis"]["confounder_selection"]["clump_kb"],
            pval_threshold = config["analysis"]["confounder_selection"]["pval_threshold"],
            find_proxies = config["analysis"]["confounder_selection"]["find_proxies"],
            population = config["analysis"]["pop"],
            harmonise_strictness = config["analysis"]["confounder_selection"]["harmonise_strictness"],
            lambda_type = lambda wc: wc.get("lambda_type"),
            seed = config["analysis"]["confounder_selection"]["seed"]
    output: out = data_dir + prefix + "selection_double_Lasso_{lambda_type}_seed{seed}.RDS"
    script: "R/5_double_Lasso.R"

rule stepwise:
    input: file = data_dir + prefix + "unique_traits.RDS"
    params: id_exposure = id_exposure,
            id_outcome = id_outcome,
            r2_thresh = config["analysis"]["confounder_selection"]["r2_thresh"],
            clump_kb = config["analysis"]["confounder_selection"]["clump_kb"],
            pval_threshold = config["analysis"]["confounder_selection"]["pval_threshold"],
            find_proxies = config["analysis"]["confounder_selection"]["find_proxies"],
            population = config["analysis"]["pop"],
            harmonise_strictness = config["analysis"]["confounder_selection"]["harmonise_strictness"],
            method = lambda wc: wc.get("stepwise_method")
    output: out = data_dir + prefix + "selection_stepwise_{stepwise_method}.RDS"
    script: "R/5_stepwise.R"

rule marginal:
    input: file = data_dir + prefix + "unique_traits.RDS",
           file_bidirection = data_dir + prefix + "downstream_filter.RDS"
    params: p_cutoff = lambda wc: wc.get("marginal_p")
    output: out = data_dir + prefix + "selection_marginal_p_{marginal_p}.RDS"
    script: "R/5_marginal.R"

rule corrected_Lasso:
    input: file = data_dir + prefix + "unique_traits.RDS"
    params: id_exposure = id_exposure,
            id_outcome = id_outcome,
            r2_thresh = config["analysis"]["confounder_selection"]["r2_thresh"],
            clump_kb = config["analysis"]["confounder_selection"]["clump_kb"],
            pval_threshold = config["analysis"]["confounder_selection"]["pval_threshold"],
            find_proxies = config["analysis"]["confounder_selection"]["find_proxies"],
            population = config["analysis"]["pop"],
            harmonise_strictness = config["analysis"]["confounder_selection"]["harmonise_strictness"],
            radius_type = lambda wc: wc.get("radius_type"),
            seed = config["analysis"]["confounder_selection"]["seed"],
            maxits = config["analysis"]["confounder_selection"]["maxits"]
    output: out = data_dir + prefix + "selection_corrected_Lasso_{radius_type}_seed{seed}.RDS"
    script: "R/5_corrected_Lasso.R"

rule double_corrected_Lasso:
    input: file = data_dir + prefix + "unique_traits.RDS"
    params: id_exposure = id_exposure,
            id_outcome = id_outcome,
            r2_thresh = config["analysis"]["confounder_selection"]["r2_thresh"],
            clump_kb = config["analysis"]["confounder_selection"]["clump_kb"],
            pval_threshold = config["analysis"]["confounder_selection"]["pval_threshold"],
            find_proxies = config["analysis"]["confounder_selection"]["find_proxies"],
            population = config["analysis"]["pop"],
            harmonise_strictness = config["analysis"]["confounder_selection"]["harmonise_strictness"],
            radius_type = lambda wc: wc.get("radius_type"),
            seed = config["analysis"]["confounder_selection"]["seed"],
            maxits = config["analysis"]["confounder_selection"]["maxits"]
    output: out = data_dir + prefix + "selection_double_corrected_Lasso_{radius_type}_seed{seed}.RDS"
    script: "R/5_double_corrected_Lasso.R"
