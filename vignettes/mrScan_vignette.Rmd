---
title: "mrScan_vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{mrScan_vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(mrScan)
library(dplyr)
library(TwoSampleMR)
library(mr.raps)
```

We'll use C-reactive protein (CRP) level (ieu-b-35) and schizophrenia (ieu-b-42) as the example. 

## Step 1: Initially extract trait list

We only search traits in ieu-a, ieu-b and ukb-b batches in this example. You can 
add more batches according to your needs. You can check list of data batches in 
IEU GWAS database by ieugwasr::batches(). In this analysis, we get 103 traits having 
at least 5 shared variants with the CRP-level.

```{r eval=FALSE}
res_step1 <- extract_traits(id_exposure = "ieu-b-35", id_outcome = "ieu-b-42",
                            batch = c("ieu-a","ieu-b","ukb-b"))
```

```{r}
load("../data/res_step1.rda")
length(res_step1$id.list)
head(res_step1$trait.info)
```

## Step 2: Quality control 

After initial filtering, we get 92 traits left. We just select traits for both gender, 
European and with the number of SNPs > 1e6. You can change the filtering standard 
by your need. You can check the info matrix for the status of each trait. 
```{r eval=FALSE}
res_step2 <- quality_control(id_exposure = "ieu-b-35",dat = res_step1$trait.info,
                             R2_cutoff = 0.85)
```


```{r}
load("../data/res_step2.rda")
length(res_step2$id.list)
head(res_step2$trait.info)
```



## Step 3: Downstream traits filtering (check cor with X and Y meanwile)

Downstream traits of both main exposure and each outcome should be deleted since 
the precision for estimating direct causal effect of the main exposure to the outcome 
could be decreased if too many genetic instruments of relationship between the main 
exposure and downstream traits were included. In this step, we will do bidirection 
MR estimates between traits and X/Y. The default method is MR-RAPs with over.dispersion=TRUE,
loss.function="tukey", and you can change it to other methods. We will select 
all upstream traits and exclude downstream traits in this step.  

After this step, we select 40 traits. The output contains select trait list, 
updated trait into matrix, and all input traits with bidirection estimates, 
t-test results. The default t-test cutoff is 0.05 and if you want to include more traits,
you can loose the cutoff to 0.1 or more. 

```{r eval=FALSE}
res_step3 <- downstream_filter(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
                               id.list = res_step2$id.list,df_info = res_step2$trait.info)
```


```{r}
load("../data/res_step3.rda")
length(res_step3$id.list)
head(res_step3$trait.info)
head(res_step3$df_bidirection)
# See selected traits
res_step3$trait.info %>% filter(id %in% res_step3$id.list)
```


## Step 4: Get unique traits

By the trait list above, we can see several similar or even duplicated traits are extracted. 
In this step, we'll calculate genetic correlation for each trait pair and select unique 
trait in each cluster.   

There are two ways to get trait correlation: 
1. Simply calculate string similarity by Jaro???Winkler distance. This way 
is quick but biased because it only based on provided trait names. If you want 
to quickly check it by this method, we recommend you to check the df_pair matrix 
and the cluster result.  

2. Calculate accurate genetic correlation by LDSC method. It will need you to download 
GWAS summary data locally and we recommend to do it on the server. You can follow 
the Snakemake pipeline for this step. 


The default clustering method is greedy clustering on the pairwise 
correlation matrix by the $R^2$ cutoff. You can also choose sample_size or nsnps method, 
which are basically selected traits with higher sample size or the number of SNPs. 
The following code example is for string similarity method.
```{r}
res_cor <- string_sim(id.list = res_step3$id.list, df_info = res_step3$trait.info)
res_step4 <- unique_traits(id.list = res_step3$id.list, df_info = res_step3$trait.info,
                           R_matrix = res_cor$R_matrix, df_pair = res_cor$df_pair,
                           R2_cutoff = 0.9, method = "cluster")
```


```{r}
length(res_step4$id.list)
res_step4$trait.info %>% filter(id %in% res_step4$id.list) %>% select(id,trait,cluster)
```



## Step 5: Confounder selection

Next, we will use different methods to do confounder selection. The potential options 
include classic Lasso, double classic Lasso, corrected Lasso, double corrected Lasso, 
marginal selection and etc. In this example, we will try different methods.
```{r}
res_step5_lasso <- confounder_selection(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
                     id.list = res_step4$id.list, df_info = res_step4$trait.info,
                     method = "classic_Lasso", lambda_type = "min")
```


```{r}
res_step5_double_lasso <- confounder_selection(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
                                               id.list = res_step4$id.list, df_info = res_step4$trait.info,
                                               method = "double_Lasso", lambda_type = "1se")
res_step5_double_lasso$id.list 
```


```{r}
res_step5_marginal <- confounder_selection(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
                                           id.list = res_step4$id.list, df_info = res_step4$trait.info,
                                           method = "marginal",df_bidirection = res_step3$df_bidirection)
res_step5_marginal$id.list
```


```{r}
res_step5_stepwise <- confounder_selection(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
                     id.list = res_step4$id.list, df_info = res_step4$trait.info,
                     method = "stepwise", stepwise_method = "forward")
res_step5_stepwise$id.list
```


```{r}
res_step5_correct <- confounder_selection(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
                     id.list = res_step4$id.list, df_info = res_step4$trait.info,
                     method = "corrected_Lasso", radius_type="1se")
res_step5_correct$id.list
```


```{r}
res_step5_double_correct <- confounder_selection(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
                     id.list = res_step4$id.list, df_info = res_step4$trait.info,
                     method = "double_corrected_Lasso", radius_type="1se")
res_step5_double_correct$id.list
```

## Step 6: MVMR analysis to get causal estimates without correlation matrix between traits

Finally, after adjusting for selected traits, we will apply different MVMR methods 
to get causal estimates from the main exposure to the outcome. The function offers 
multiple MVMR methods including regular MV-IVW, MV-median and more robust methods 
like GRAPPLE, MRBEE. In this step, we assume traits are independent with each other. 
Here we use traits selected from double corrected Lasso as the example.

```{r}
res_final_ivw <- MVMR_analysis(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
              id.list = res_step5_double_correct$id.list,
              df_info = res_step5_double_correct$trait.info,
              MVMR_method = "IVW")
res_final_ivw_T <- MVMR_analysis(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
              id.list = res_step5_double_correct$id.list,
              df_info = res_step5_double_correct$trait.info,
              MVMR_method = "IVW_instrument_specific")
res_final_bee <- MVMR_analysis(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
              id.list = res_step5_double_correct$id.list,
              df_info = res_step5_double_correct$trait.info,
              MVMR_method = "MRBEE",pleio_p_thresh = 0)
res_final_grapple <- MVMR_analysis(id_exposure = "ieu-b-35",id_outcome = "ieu-b-42",
              id.list = res_step5_double_correct$id.list,
              df_info = res_step5_double_correct$trait.info,
              MVMR_method = "GRAPPLE")

```


Get direct causal estimates of CRP-level on schizophrenia by different methods:
```{r}
rbind(res_final_ivw,res_final_ivw_T) %>% dplyr::select(id.exposure,b,se,pval,method) %>%
  rename("exposure" = "id.exposure","pvalue" = "pval") %>%
  rbind(res_final_bee,res_final_grapple) %>%
  filter(exposure == "ieu-b-35")
```

## Step 7: MVMR analysis to get causal estimates with correlation matrix between traits

In order to take genetic correlation between traits into consideration, we need to 
estimate it first. You need to download raw GWAS summary statistics to local. You 
can save files on the server since they could be pretty large. 

### 1. Download GWAS summary statistics

You can use the following code to generate download.sh file and conduct it in the 
linux command line. The default position to save this file is your current working 
directory and you can change it by position parameter.
```{r}
download_gwas(id_list = c("ieu-b-35","ieu-b-42",
                          res_step5_double_correct$id.list))
```


```{bash, eval=FALSE, engine="sh"}
bash download.sh
```

### 2. Formatting and harmonize data

After downloading data, next step is to format raw GWAS summary data to remove 
ambiguous SNPs. The following code uses ieu-b-42, ieu-b-35 and ieu-b-104 as the example, and you can 
format each trait by the same rule. Put the outcome as the first trait.
```{r eval=FALSE}
library(stringr)
library(readr)
library(VariantAnnotation)
library(gwasvcf)
library(dplyr)
library(magrittr)
library(rlang)
library(purrr)
format_combine_gwas(id_list = c("ieu-b-42","ieu-b-35","ukb-b-19953"),
               file_list = c("ieu-b-42.vcf.gz","ieu-b-35.vcf.gz","ukb-b-19953.vcf.gz"),
               out_dir="data/",prefix="test")
```

### 3. LD clumping

You can download the LD reference dataset from here http://fileserve.mrcieu.ac.uk/ld/1kg.v3.tgz
This contains an LD reference panel for each of the 5 super-populations in the 1000 genomes reference dataset.
```{r}
ld_prune_chrom_plink(beta_dir = "data/",prefix = "test",ref_path = "/path/LD_reference/EUR",
                     out_dir = "/path/ld_prune_output/")
```

### 4. Calculate R correlation matrix

There are two options for this. One is by using pvalue method and the other is LDSC way. 
pvalue method is quick and easier but the estimated matrix could be biased. If you want to 
use more accurate LDSC way, you need to download reference LD score first. 

```{r eval=FALSE}
estimate_R_pval(ld_prune_file_dir = "/path/ld_prune_output/",prefix = "test",
                out_dir = "data/")
```


```{r eval=FALSE}
ldsc_full(l2_dir = "/path/l2_dir/",beta_dir = "data/",prefix = "test",out_dir = "data/")
```


```{r}
test.R_est_ldsc <- readRDS("data/test.R_est_ldsc.RDS")
test.R_est_pval <- readRDS("data/test.R_est_pval.RDS")
test.R_est_ldsc
test.R_est_pval
```


### 5. Get MVMR estimates with R matrix
```{r}
res_grapple_R <- MVMR_analysis_local(ld_prune_file_dir = "/path/ld_prune_output/",
                    prefix = "test",R = test.R_est_ldsc,
                    p_thresh = 1e-5,MVMR_method = "GRAPPLE")
res_bee_R <- MVMR_analysis_local(ld_prune_file_dir = "/path/ld_prune_output/",
                    prefix = "test",R = test.R_est_ldsc,
                    p_thresh = 5e-8, pleio_p_thresh = 0,
                    MVMR_method = "MRBEE")
res_ivw <- MVMR_analysis_local(ld_prune_file_dir = "/path/ld_prune_output/",
                    prefix = "test",p_thresh = 5e-8,
                    MVMR_method = "IVW")
```


